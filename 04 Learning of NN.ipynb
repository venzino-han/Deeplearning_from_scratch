{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Fuction / Cost Function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*가장 많이 쓰이는 것은 평균 제곱 오차 MSE(mean squared error) <br>\n",
    "![](img/022.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y,t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18500000000000005"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5550000000000002"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=np.array([0,0,1,0,0,0,0,0,0,0]) # 정답 2\n",
    "y1=np.array([0,0.1,0.6,0,0.4,0,0.2,0,0,0]) # 2로 예측\n",
    "y2=np.array([0,0.1,0.5,0,0.4,0.1,0.2,0,0.8,0]) # 9로 예측 오답\n",
    "mean_squared_error(y1,t)\n",
    "mean_squared_error(y2,t)\n",
    "mean_squared_error(t,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 교차 엔트로피 오차 Cross Entropy Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/023.jpg)![](img/024.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    delta = 1e-7 # 0이 입력되는것을 방지 --> 0일 경우 결과 값이 음의 무한대로가게됨\n",
    "    return -np.sum(t*np.log(y+delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6931469805599654"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-9.999999505838704e-08"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(y1,t) #정답\n",
    "cross_entropy_error(y2,t) #오답\n",
    "cross_entropy_error(t,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미니배치 학습\n",
    "#### 1. 훈련데이터에 대한 손실함수값 구하기\n",
    "#### 2. 손실함수 값을 최소화하는 매개변수 찾아내기 \n",
    "#### 3. 모든 훈련데이터를 대상으로 손실함수값을 구해서 합함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 미니배치를 고려한 손실함수 수식<br>\n",
    "![](img/025.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize =1, one_hot_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "t_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53815, 30651, 48173, 42846, 33067,  6465, 32472, 50606,  3405,\n",
       "       28545])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([29449, 41900, 38091, 23119, 46644,  5530, 10125, 25892, 32786,\n",
       "       52480])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#무작위로 10개 추출 \n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "batch_mask\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]\n",
    "\n",
    "np.random.choice(60000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 교차 엔트로피 오차 구현하기 (배치용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cros_entropy_error(y,t):\n",
    "    if y.ndim == 1:             # y가 1차원 배열일 경우\n",
    "        t= t.reshape(1,t.size)  # 차원 추가\n",
    "        y= y.reshape(1,y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t*np.log(y+ 1e-7)) / batch_size # 교차 엔트로피 오차의 총합을 구한 뒤 배치 사이즈로 나누어 정규화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#원핫 인코딩이 아닌 '2'등의 숫자 레이블의 경우\n",
    "#교차 엔트로피 오차\n",
    "\n",
    "def cross_entropy_error_non_onehot(y,t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size),t])) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batch_size == 5 일 경우\n",
    "- np.arange(batch_size) --> [0,1,2,3,4] 배열 생성\n",
    "- t 에 있는 레이블 --> [2,7,0,9,4]  \n",
    "- y[np.arange(batch_size),t] -- > 각 데이터의 정답 레이블과 신경망 출력을 세트로 출력  --> [y[0,2], y[1,7], y[2,0], y[3,9], y[4,4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 왜 손실함수를 사용하는가?\n",
    "#### 정확도 대신 손실함수값을 사용하는 이유 \n",
    "* 신경망 학습에서 '미분'의 역할에 주목 \n",
    "* 손실함수 값을 최소화 하는 매개변수 값을 찾는다 (가중치와 편향 탐색)\n",
    "* 매개변수의 미분을 계산하고 미분값을 단서로 매개변수의 값을 갱신하는 과정을 반복\n",
    "\n",
    "---------------------------------\n",
    "\n",
    "* 가중치 매개변수의 손실함수의 미분 --> 가중치의 값을 조금 변화시킬때 손실함수가 어떻게 변하는가?<br>\n",
    "* 미분값 [음수] --> 가중치 매개변수를 증가 --> 손실함수값 감소<br>\n",
    "* 미분값 [양수] --> 가중치 매개변수 감소 --> 손실함수값 감소<br>\n",
    "* 미분값 0 --> 손실함수값이 최저임 지점이라 판단함 <br>\n",
    "####  ※ 정확도를 지표로 삼을 경우 미분값이 대부분의 장소에서 0이 되어 매개변수를 갱신할 수 없다!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 계단함수를 사용하지 않는 것도 같은 이유<br>\n",
    "![](img/026.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수치 미분\n",
    "### 미분, 편미분의 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수치 미분에는 오차가 발생한다. \n",
    "#### 실제 접선과 수치미분(근사로 구한 접선) 기울기의 차이 존재함\n",
    "![](img/027.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  중심차분 : x전후 값의 차분\n",
    "*  전방차분 : x , x+h 값의 차분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치미분의 구현 \n",
    "def numerical_diff(f,x):\n",
    "    h = 1e-4\n",
    "    return (f(x+h) - f(x-h)) / (2*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치미분의 예시\n",
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fbb5dc9278>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0.0, 20.0, 0.1) #배열 생성\n",
    "y = function_1(x)\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1999999999990898"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.2999999999986347"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = 5, x=10 일때의 미분값 \n",
    "numerical_diff(function_1, 5) # 실제값 0.2\n",
    "numerical_diff(function_1, 10) # 실제값 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 편미분 : 변수가 2개 이상인 경우 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 편미분할 함수 구현\n",
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/028.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.00000000000378"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x0=3 x1=4 일때 x0에 대한 편미분\n",
    "def function_tmp1(x0):\n",
    "    return x0*x0 + 4**2\n",
    "\n",
    "numerical_diff(function_tmp1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.999999999999119"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x0=3 x1=4 일때 x1에 대한 편미분\n",
    "def function_tmp2(x1):\n",
    "    return 3**2 + x1**2\n",
    "\n",
    "numerical_diff(function_tmp2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기울기\n",
    "#### 모든 변수에 대해 편미분을 동시에 계산하여 벡터로 정의 --> 기울기(Gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient 구현\n",
    "def numerical_gradient(f,x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x) # x와 같은 형상의 배열 생성\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        \n",
    "        x[idx] = tmp_val + h # f(x+h) 계산\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - h # f(x-h) 계산\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 4.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#각 지점에서의 개별 기울기\n",
    "numerical_gradient(function_2,np.array([3.,4.]))\n",
    "numerical_gradient(function_2,np.array([0.0,2.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 벡터로 표현 : 낮은곳으로 갈수록 기울기 감소\n",
    "![](img/029.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경사하강법의 등장 \n",
    "\n",
    "#### 안장점이나, 국소적인 최소값이 극솟값 등 벡터가 가리키는 곳이 최소값이 아닌경우도 있다!\n",
    "\n",
    "1. 현 위치에서 기울어진 방향으로 일정 거리만큼 이동 \n",
    "2. 이동한 위치에서 기울기를 구함\n",
    "3. 1번 을 반복 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 경사하강법 수식 표현\n",
    "##### eta 는 learing rate 를 의미\n",
    "![](img/030.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#경사하강법 구현 \n",
    "def gradient_descent(f,init_x, lr=0.01, step_num=100):\n",
    "    x = init_x #초기 시작지점 \n",
    "    \n",
    "    for i in range(step_num):  #정해놓은 스템 수 만큼 경사하강을 한다.\n",
    "        grad = numerical_gradient(f,x)\n",
    "        x -= lr * grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grad descent 로 최소값 구하기\n",
    "gradient_descent(function_2, np.array([-3.,4.]) , lr=0.1, step_num=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/031.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.58983747e+13, -1.29524862e+12])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(function_2, np.array([-3.,4.]) , lr=10, step_num=100) \n",
    "# learning rate 가 너무 큰 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.99999994,  3.99999992])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(function_2, np.array([-3.,4.]) , lr=1e-10, step_num=100)\n",
    "# learning rate 가 너무 작은 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망에서의 기울기 \n",
    "#### 기울기 -> 가중치 매개변수에 대한 손실 함수의 기울기 \n",
    "#### 형상 2*3 가중치 W 손실함수 L 인 경우      경사는 dL/dW 로 표현\n",
    "![](img/032.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기울기 구하는 코드 \n",
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2,3) # 정규분포로 초기화된 2*3 행렬 생성\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W) #행렬곱\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y,t)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01235625  1.01839205  0.6570892 ]\n",
      " [-0.21602419  0.66116951  0.38981433]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "net = simpleNet()\n",
    "print(net.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.18700802,  1.20608779,  0.74508642])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([.6,.9])\n",
    "p = net.predict(x)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p) # 최대값 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.023812010322066"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t= np.array([1,0,0]) # 정답 레이블\n",
    "net.loss(x,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기울기 구하기 \n",
    "#### numerical gradient를 사용하여 구함 W는 더미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(W):\n",
    "    return net.loss(x,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52070922,  0.31932582,  0.2013834 ],\n",
       "       [-0.78106383,  0.47898872,  0.30207511]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW = numerical_gradient(f, net.W)\n",
    "dW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 위의 출력 값은 W값의 변화에 손실 함수 값이 얼마나 변하는지를 보여줌\n",
    "##### a라는 값이 나오면 w를 h만큼 증가시키면 \n",
    "##### 손실함수는 a*h만큼 증가함 \n",
    "##### a 값이 음수인 경우 w값이 증가하면 손실함수 값 감소  --> 손실함수를 줄이는 방향으로 W를 갱신해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52070922,  0.31932582,  0.2013834 ],\n",
       "       [-0.78106383,  0.47898872,  0.30207511]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda w: net.loss(x,t)\n",
    "dW = numerical_gradient(f, net.W)\n",
    "dW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 알고리즘 구현하기 \n",
    "- 전제 : 신경망에는 적응 가능한 W,b 존재 --> W,b를 훈련데이터에 적응하도록 조정하는 과정을 '학습'이라 부름 \n",
    "- 1단계 미니배치 : 훈련데이터를 무작위로 가져옴, 손실함수 값을 줄이는 것이 목표\n",
    "- 2단계 기울기 산출 : 가중치 매개변수의 기울기를 구함 --> 손실함수 값을 줄이는 방향을 제시\n",
    "- 3단계 매개변수 갱신 : 가중치 매개변수를 기울기 방향으로 조금씩 갱신\n",
    "- 4단계 1-3 단계를 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 미니배치로 무작위 선정하는 것을 \"확률적 경사하강법 (Stochastic gradient decent)\" 라고 부르며 SGD로 불리며 함수로제공된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2층 신경망 클래스 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01 ):\n",
    "        #가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.rand(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.rand(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x, W1) +b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) +b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    # 입력 x, 정답 라벨 t\n",
    "    def loss(self, x, t):\n",
    "        y= self.predict(x)\n",
    "        return cross_entropy_error(y,t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y ==t)/ float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x,t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/033.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 100)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)\n",
    "net.params['W1'].shape\n",
    "net.params['b1'].shape\n",
    "net.params['W2'].shape\n",
    "net.params['b2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(100,784) # 더미데이터 생성\n",
    "y = net.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-d6dbfd7e0059>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#정답레이블\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgrands\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#기울기 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-115-5166ee5b39cd>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PYTHON\\Deeplearning from scratch\\common\\gradient.py\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mfxh2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# f(x-h)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfxh1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfxh2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-115-5166ee5b39cd>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mloss_W\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-115-5166ee5b39cd>\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# 입력 x, 정답 라벨 t\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-115-5166ee5b39cd>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0ma1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mb1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mz1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t = np.random.rand(100,10) #정답레이블\n",
    "\n",
    "grands = net.numerical_gradient(x,t) #기울기 계산\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grands['W1'].shape\n",
    "grands['b1'].shape\n",
    "grands['W2'].shape\n",
    "grands['b2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미니배치 학습 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.mnist import load_mnist\n",
    "#from two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "#하이퍼 파라메터 / 시간관계상 짧게 처리 \n",
    "iters_num = 10 #반복횟수\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100 #미니배치 크기\n",
    "learning_rate = 1\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    #미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    #기울기 계산\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    \n",
    "    #매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    #학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fbb5e2e7b8>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list)\n",
    "plt.rcParams[\"figure.figsize\"] = (4,2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/034.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시험 데이터로 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.mnist import load_mnist\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "#하이퍼 파라메터 / 시간관계상 짧게 처리 \n",
    "iters_num = 1000 #10000 에서 시간관계상 줄임\n",
    "train_size = int(x_train.shape[0]/10) #60000에서 시간관계상 1/10으로 줄임\n",
    "batch_size = 100\n",
    "learning_rate = 0.5 # 0.1\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list= []\n",
    "\n",
    "#1epoch 당 반복 횟수 \n",
    "iter_per_epoch = max(train_size/batch_size,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(iters_num):\n",
    "    #미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    #기울기 계산\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    #grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    #매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    #학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1epoch 당 정확도 계산\n",
    "    if i % iter_per_epoch ==0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_acc_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/035.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
